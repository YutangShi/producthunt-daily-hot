import os

# from dotenv import load_dotenv
import requests
from datetime import datetime, timedelta, timezone
from openai import OpenAI
from bs4 import BeautifulSoup
import pytz

# åŠ è¼‰ .env æ–‡ä»¶
# load_dotenv()

# å‰µå»º OpenAI å®¢æˆ¶ç«¯å¯¦ä¾‹
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

producthunt_client_id = os.getenv("PRODUCTHUNT_CLIENT_ID")
producthunt_client_secret = os.getenv("PRODUCTHUNT_CLIENT_SECRET")
product_hunt_token = os.getenv("PRODUCT_HUNT_TOKEN")


class Product:
    def __init__(
        self,
        id: str,
        name: str,
        tagline: str,
        description: str,
        votesCount: int,
        createdAt: str,
        featuredAt: str,
        website: str,
        url: str,
        **kwargs,
    ):
        self.name = name
        self.tagline = tagline
        self.description = description
        self.votes_count = votesCount
        self.created_at = self.convert_to_beijing_time(createdAt)
        self.featured = "æ˜¯" if featuredAt else "å¦"
        self.website = website
        self.url = url
        self.og_image_url = self.fetch_og_image_url()
        self.keyword = self.generate_keywords()
        self.translated_tagline = self.translate_text(self.tagline)
        self.translated_description = self.translate_text(self.description)

    def fetch_og_image_url(self) -> str:
        """ç²å–ç”¢å“çš„Open Graphåœ–ç‰‡URL"""
        response = requests.get(self.url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "html.parser")
            og_image = soup.find("meta", property="og:image")
            if og_image:
                return og_image["content"]
        return ""

    def generate_keywords(self) -> str:
        """ç”Ÿæˆç”¢å“çš„é—œéµè©ï¼Œé¡¯ç¤ºåœ¨ä¸€è¡Œï¼Œç”¨é€—è™Ÿåˆ†éš”"""
        prompt = f"æ ¹æ“šä»¥ä¸‹å…§å®¹ç”Ÿæˆé©åˆçš„ä¸­æ–‡é—œéµè©ï¼Œç”¨è‹±æ–‡é€—è™Ÿåˆ†éš”é–‹ï¼š\n\nç”¢å“åç¨±ï¼š{self.name}\n\næ¨™èªï¼š{self.tagline}\n\næè¿°ï¼š{self.description}"

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Generate suitable Chinese keywords based on the product information provided. The keywords should be separated by commas.",
                    },
                    {"role": "user", "content": prompt},
                ],
                max_tokens=50,
                temperature=0.7,
            )
            keywords = response.choices[0].message.content.strip()
            if "," not in keywords:
                keywords = ", ".join(keywords.split())
            return keywords
        except Exception as e:
            print(f"Error occurred during keyword generation: {e}")
            return "ç„¡é—œéµè©"

    def translate_text(self, text: str) -> str:
        """ä½¿ç”¨OpenAIç¿»è­¯æ–‡æœ¬å…§å®¹"""
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸–ç•Œä¸Šæœ€å°ˆæ¥­çš„ç¿»è­¯å·¥å…·ï¼Œæ“…é•·è‹±æ–‡å’Œä¸­æ–‡äº’è­¯ã€‚ä½ æ˜¯ä¸€ä½ç²¾é€šè‹±æ–‡å’Œä¸­æ–‡çš„å°ˆæ¥­ç¿»è­¯ï¼Œå°¤å…¶æ“…é•·å°‡ITå…¬å¸é»‘è©±å’Œå°ˆæ¥­è©å½™ç¿»è­¯æˆç°¡æ½”æ˜“æ‡‚çš„åœ°é“è¡¨é”ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯æˆæµæš¢çš„ç¹é«”ä¸­æ–‡ï¼Œé¢¨æ ¼èˆ‡ç§‘æ™®é›œèªŒæˆ–æ—¥å¸¸å°è©±ç›¸ä¼¼ã€‚",
                    },
                    {"role": "user", "content": text},
                ],
                max_tokens=500,
                temperature=0.7,
            )
            translated_text = response.choices[0].message.content.strip()
            return translated_text
        except Exception as e:
            print(f"Error occurred during translation: {e}")
            return text

    def convert_to_beijing_time(self, utc_time_str: str) -> str:
        """å°‡UTCæ™‚é–“è½‰æ›ç‚ºå°ç£æ™‚é–“"""
        utc_time = datetime.strptime(utc_time_str, "%Y-%m-%dT%H:%M:%SZ")
        beijing_tz = pytz.timezone("Asia/Taipei")
        beijing_time = utc_time.replace(tzinfo=pytz.utc).astimezone(beijing_tz)
        return beijing_time.strftime("%Yå¹´%mæœˆ%dæ—¥ %p%I:%M (å°ç£æ™‚é–“)")

    def to_markdown(self, rank: int) -> str:
        """è¿”å›ç”¢å“æ•¸æ“šçš„Markdownæ ¼å¼"""
        og_image_markdown = f"![{self.name}]({self.og_image_url})"
        return (
            f"## [{rank}. {self.name}]({self.url})\n"
            f"**æ¨™èª**ï¼š{self.translated_tagline}\n"
            f"**ä»‹ç´¹**ï¼š{self.translated_description}\n"
            f"**ç”¢å“ç¶²ç«™**: [ç«‹å³è¨ªå•]({self.website})\n"
            f"**Product Hunt**: [View on Product Hunt]({self.url})\n\n"
            f"{og_image_markdown}\n\n"
            f"**é—œéµè©**ï¼š{self.keyword}\n"
            f"**ç¥¨æ•¸**: ğŸ”º{self.votes_count}\n"
            f"**æ˜¯å¦ç²¾é¸**ï¼š{self.featured}\n"
            f"**ç™¼ä½ˆæ™‚é–“**ï¼š{self.created_at}\n\n"
            f"---\n\n"
        )

    # def get_producthunt_token():
    """é€šé client_id å’Œ client_secret ç²å– Product Hunt çš„ access_token"""
    url = "https://api.producthunt.com/v2/oauth/token"
    # payload = {
    #     "client_id": producthunt_client_id,
    #     "client_secret": producthunt_client_secret,
    #     "grant_type": "client_credentials",
    # }

    # headers = {
    #     "Content-Type": "application/json",
    # }

    # response = requests.post(url, json=payload, headers=headers)

    # if response.status_code != 200:
    #     raise Exception(
    #         f"Failed to obtain access token: {response.status_code}, {response.text}"
    #     )

    # token = response.json().get("access_token")
    # return token


def fetch_product_hunt_data():
    """å¾ Product Hunt å–å¾—å–å‰ä¸€å¤©çš„Top 30æ•¸æ“š"""
    token = product_hunt_token
    print(product_hunt_token)
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime("%Y-%m-%d")
    url = "https://api.producthunt.com/v2/api/graphql"
    headers = {"Authorization": f"Bearer {token}"}

    base_query = """
    {
      posts(order: VOTES, postedAfter: "%sT00:00:00Z", postedBefore: "%sT23:59:59Z", after: "%s") {
        nodes {
          id
          name
          tagline
          description
          votesCount
          createdAt
          featuredAt
          website
          url
        }
        pageInfo {
          hasNextPage
          endCursor
        }
      }
    }
    """

    all_posts = []
    has_next_page = True
    cursor = ""

    while has_next_page and len(all_posts) < 30:
        query = base_query % (date_str, date_str, cursor)
        response = requests.post(url, headers=headers, json={"query": query})

        if response.status_code != 200:
            raise Exception(
                f"Failed to fetch data from Product Hunt: {response.status_code}, {response.text}"
            )

        data = response.json()["data"]["posts"]
        posts = data["nodes"]
        all_posts.extend(posts)

        has_next_page = data["pageInfo"]["hasNextPage"]
        cursor = data["pageInfo"]["endCursor"]

    # åªä¿ç•™å‰30å€‹ç”¢å“
    return [
        Product(**post)
        for post in sorted(all_posts, key=lambda x: x["votesCount"], reverse=True)[:30]
    ]


def generate_markdown(products, date_str):
    """ç”ŸæˆMarkdownå…§å®¹ä¸¦ä¿å­˜åˆ°dataç›®éŒ„"""
    # ç²å–ä»Šå¤©çš„æ—¥æœŸä¸¦æ ¼å¼åŒ–
    today = datetime.now(timezone.utc)
    date_today = today.strftime("%Y-%m-%d")

    markdown_content = f"# ä»Šæ—¥ç†±é–€æ¦œå–® | {date_today}\n\n"
    for rank, product in enumerate(products, 1):
        markdown_content += product.to_markdown(rank)

    # ç¢ºä¿ data ç›®éŒ„å­˜åœ¨
    os.makedirs("data", exist_ok=True)

    # ä¿®æ”¹æ–‡ä»¶ä¿å­˜è·¯å¾‘åˆ° data ç›®éŒ„
    file_name = f"data/producthunt-daily-{date_today}.md"

    # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¦†è“‹
    with open(file_name, "w", encoding="utf-8") as file:
        file.write(markdown_content)
    print(f"æ–‡ä»¶ {file_name} ç”¢ç”ŸæˆåŠŸä¸¦æ›´æ–°ã€‚")


def main():
    # ç²å–æ˜¨å¤©çš„æ—¥æœŸä¸¦æ ¼å¼åŒ–
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime("%Y-%m-%d")

    # ç²å–Product Huntæ•¸æ“š
    products = fetch_product_hunt_data()

    # ç”ŸæˆMarkdownæ–‡ä»¶
    generate_markdown(products, date_str)


if __name__ == "__main__":
    main()
